# Stream processing

## Database inside out
Типичные базы данных хранят состояние внутри себя.  Но в рамках микросервисной архитектуры какая-часть этого состояния
должна быть пошарена (shared) с другими микросервисами.  
По большому счету одно и то же состояние, но имеющее разные представления, может хранится в разных сервисах.  
Типичный пример это реализация поиска. Данные нужны и в базе и в индексе.  

### Что мы получаем?
Лучшее представление данных:
- Поток событий для аналитиков – намного лучше просто состояния
- Разделение данных для записи и чтения
- Пиши один раз, и можешь читать из множества разных представлений для чтений
- Лучшая защита от ошибок (человеческий фактор)
- Темпоральные запросы и восстановление
- Хорошие кэши: Больше никакого разогрева кэшей, hit/miss rate, никаких гонок, никакой больше сложной логики инвалидации, лучшая изоляция и надежность.

### Что же делать?
Соответственно, нам нужна специализированная БД, которая бы могла хранить поток событий, и могла бы эти изменения  транслировать дальше.
Такой БД является, например, Kafka.  
Kafka – не только брокер сообщений, но и база данных.  
Kafka предназначена для того, чтобы быть хранилищем, и брокером событий (сообщений).  

### Kafka Streams
Kafka streams - инструмент для упрощения Stream Processing-а
Stream – это поток **типизированых** сообщений (событий).  
Table – это агрегация потока (стрима).  
По факту в этой схеме получается так что для каждого ключа в табличку записывается только последнее значение.

### Практический пример с Kafka
[тут](labs/05-stream-processing/kafka/README.md)

## Change data capture
По факту это публикация данных из DB в очереди.
Из инструментов можно посмотреть на **Debezium**

### Практический пример с Debezium
[тут](labs/05-stream-processing/debezium/README.md)
